# NDSD-Fusion

This is a official code release of NDSD-Fusion for 3D Object Detection. 

## Getting Started

conda create -n ndsd python=3.9
conda activate ndsd
pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html
pip install numpy==1.19.5 protobuf==3.19.4 scikit-image==0.19.2 waymo-open-dataset-tf-2-5-0 nuscenes-devkit==1.0.5 spconv-cu111 numba scipy pyyaml easydict fire tqdm shapely matplotlib opencv-python addict pyquaternion awscli open3d pandas future pybind11 tensorboardX tensorboard Cython prefetch-generator

Dependency

Ubuntu 18.04
Python 3.9.21
PyTorch 1.8.1
Numba 0.56.4
Spconv 2.3.8
NVIDIA CUDA 11.1
4 GeForce RTX 3090Ti GPUs



Prepare dataset

KITTI dataset: Similar to VirConv [here], the pseudo points can be generated by the PENET method.
MLFIS dataset: The pseudo points can be generated through projecting the RGB image pixels onto the LiDAR points.

Anyway, the data structure should be:

ndsd
├── data
│   ├── kitti
│   │   │── ImageSets
│   │   │── training
│   │   │   ├──calib & velodyne & label_2 & image_2 & (optional: planes) & velodyne_depth
│   │   │── testing
│   │   │   ├──calib & velodyne & image_2 & velodyne_depth
│   │   │── gt_database_mm
│   │   │── kitti_dbinfos_train_mm.pkl
│   │   │── kitti_infos_test.pkl
│   │   │── kitti_infos_train.pkl
│   │   │── kitti_infos_trainval.pkl
│   │   │── kitti_infos_val.pkl
├── pcdet
├── tools


Setup

cd ndsd
python setup.py develop

Training and Validation.

For training the ndsd:

Single GPU train:

cd tools
python3 train.py --cfg_file ${CONFIG_FILE}

Multiple GPU train:

cd tools
CUDA_VISIBLE_DEVICES=0,1,2,3  python3 -m torch.distributed.launch --nproc_per_node=4 --master_addr="localhost" --master_port=29501 train.py  --launcher pytorch > log.txt&


Evaluation.
cd tools
python3 test.py --cfg_file ${CONFIG_FILE} --batch_size ${BATCH_SIZE} --ckpt ${CKPT}

Acknowledgement

Virconv

SIIV

OpenPCDet

LoGoNet
